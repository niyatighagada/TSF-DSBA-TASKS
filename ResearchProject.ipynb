{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1TgNlz6gmvtNOVkZTdRr9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niyatighagada/TSF-DSBA-TASKS/blob/main/ResearchProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ATxf0pQIYj_R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
        "RANDOM_SEED = 2021 \n",
        "TEST_PCT = 0.3\n",
        "LABELS = [\"Normal\",\"Abnormal\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"ATP Dataset_2012-01 to 2017-07_Int_V4.csv\")\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "r_7P2MC_YriA",
        "outputId": "fe4806fc-a93a-4a53-8f06-1f783bedb52a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ATP             Tournament  Tournament_Int   Date  Series  Series_Int  \\\n",
              "0    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "1    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "2    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "3    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "4    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "\n",
              "     Court  Court_Int Surface  Surface_Int  ... Player1_Int     Player2  \\\n",
              "0  Outdoor     3.6494    Hard       4.4983  ...      6.7633  ThompsonJ.   \n",
              "1  Outdoor     3.6494    Hard       4.4983  ...      6.9297    RobertS.   \n",
              "2  Outdoor     3.6494    Hard       4.4983  ...      6.5792    FerrerD.   \n",
              "3  Outdoor     3.6494    Hard       4.4983  ...      6.8384  EscobedoE.   \n",
              "4  Outdoor     3.6494    Hard       4.4983  ...      6.7032  DimitrovG.   \n",
              "\n",
              "   Player2_Int Player1_Rank  Player2_Rank Player1_Odds  Player2_Odds  \\\n",
              "0       6.7926        160.0          79.0         3.50          1.29   \n",
              "1       6.9686         39.0          54.0         1.54          2.43   \n",
              "2       6.3881         26.0          21.0         1.77          2.01   \n",
              "3       6.0929         45.0         141.0         1.37          3.01   \n",
              "4       6.5157         33.0          17.0         2.85          1.41   \n",
              "\n",
              "  Player1_Implied_Prob  Player2_Implied_Prob  Class  \n",
              "0               0.2857                0.7752      0  \n",
              "1               0.6494                0.4115      0  \n",
              "2               0.5650                0.4975      1  \n",
              "3               0.7299                0.3322      1  \n",
              "4               0.3509                0.7092      0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dea19077-42b3-4287-aa63-c92457de3ec8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ATP</th>\n",
              "      <th>Tournament</th>\n",
              "      <th>Tournament_Int</th>\n",
              "      <th>Date</th>\n",
              "      <th>Series</th>\n",
              "      <th>Series_Int</th>\n",
              "      <th>Court</th>\n",
              "      <th>Court_Int</th>\n",
              "      <th>Surface</th>\n",
              "      <th>Surface_Int</th>\n",
              "      <th>...</th>\n",
              "      <th>Player1_Int</th>\n",
              "      <th>Player2</th>\n",
              "      <th>Player2_Int</th>\n",
              "      <th>Player1_Rank</th>\n",
              "      <th>Player2_Rank</th>\n",
              "      <th>Player1_Odds</th>\n",
              "      <th>Player2_Odds</th>\n",
              "      <th>Player1_Implied_Prob</th>\n",
              "      <th>Player2_Implied_Prob</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.7633</td>\n",
              "      <td>ThompsonJ.</td>\n",
              "      <td>6.7926</td>\n",
              "      <td>160.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.29</td>\n",
              "      <td>0.2857</td>\n",
              "      <td>0.7752</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.9297</td>\n",
              "      <td>RobertS.</td>\n",
              "      <td>6.9686</td>\n",
              "      <td>39.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1.54</td>\n",
              "      <td>2.43</td>\n",
              "      <td>0.6494</td>\n",
              "      <td>0.4115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.5792</td>\n",
              "      <td>FerrerD.</td>\n",
              "      <td>6.3881</td>\n",
              "      <td>26.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.77</td>\n",
              "      <td>2.01</td>\n",
              "      <td>0.5650</td>\n",
              "      <td>0.4975</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.8384</td>\n",
              "      <td>EscobedoE.</td>\n",
              "      <td>6.0929</td>\n",
              "      <td>45.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1.37</td>\n",
              "      <td>3.01</td>\n",
              "      <td>0.7299</td>\n",
              "      <td>0.3322</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.7032</td>\n",
              "      <td>DimitrovG.</td>\n",
              "      <td>6.5157</td>\n",
              "      <td>33.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.85</td>\n",
              "      <td>1.41</td>\n",
              "      <td>0.3509</td>\n",
              "      <td>0.7092</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dea19077-42b3-4287-aa63-c92457de3ec8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dea19077-42b3-4287-aa63-c92457de3ec8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dea19077-42b3-4287-aa63-c92457de3ec8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for any  nullvalues \n",
        "print(\"Any nulls in the dataset \",dataset.isnull().values.any() )\n",
        "print('-------')\n",
        "print(\"No. of unique labels \", len(dataset['Class'].unique()))\n",
        "print(\"Label values \",dataset.Class.unique())\n",
        "#0 is for normal event\n",
        "#1 is for abnormal event\n",
        "print('-------')\n",
        "print(\"Break down of the Normal and Abnormal Events\")\n",
        "print(pd.value_counts(dataset['Class'], sort = True) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hdMOdHeQYvaG",
        "outputId": "592252aa-5baf-4ba3-8faf-cba25834f864"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Any nulls in the dataset  True\n",
            "-------\n",
            "No. of unique labels  2\n",
            "Label values  [0 1]\n",
            "-------\n",
            "Break down of the Normal and Abnormal Events\n",
            "0    12773\n",
            "1     1962\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the imbalanced dataset\n",
        "count_classes = pd.value_counts(dataset['Class'], sort = True)\n",
        "count_classes.plot(kind = 'bar', rot=0)\n",
        "plt.xticks(range(len(dataset['Class'].unique())), dataset.Class.unique())\n",
        "plt.title(\"Frequency by observation number\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Number of Observations\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0Hjgtf81Y3Po",
        "outputId": "5d791570-ca53-482c-c107-392837146d83"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the normal and fradulent transactions in separate dataframe\n",
        "normal_dataset = dataset[dataset.Class == 0] \n",
        "abnormal_dataset = dataset[dataset.Class == 1]\n",
        "#Visualize transactionamounts for normal and fraudulent transactions\n",
        "bins = np.linspace(200, 2500, 100)\n",
        "plt.hist(normal_dataset.Player1_Rank, bins=bins, alpha=1, density=True, label='Normal')\n",
        "plt.hist(abnormal_dataset.Player1_Rank, bins=bins, alpha=0.5, density=True, label='Abnormal')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title(\"Player 1 Rank vs Percentage of Rankings\")\n",
        "plt.xlabel(\"Player 1 Rank\")\n",
        "plt.ylabel(\"Percentage of Rankings\");\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ANJXxT0rbc0C",
        "outputId": "b90b7075-7e10-4838-eda6-35a6e3d2fcac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the normal and fradulent transactions in separate dataframe\n",
        "normal_dataset = dataset[dataset.Class == 0] \n",
        "abnormal_dataset = dataset[dataset.Class == 1]\n",
        "#Visualize transactionamounts for normal and fraudulent transactions\n",
        "bins = np.linspace(200, 2500, 100)\n",
        "plt.hist(normal_dataset.Player2_Rank, bins=bins, alpha=1, density=True, label='Normal')\n",
        "plt.hist(abnormal_dataset.Player2_Rank, bins=bins, alpha=0.5, density=True, label='Abnormal')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title(\"Player 2 Rank vs Percentage of Rankings\")\n",
        "plt.xlabel(\"Player 2\")\n",
        "plt.ylabel(\"Percentage of Rankings\");\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ggLTdDpcOZCi",
        "outputId": "630e36b2-b709-4e8c-dcd7-81108464a98d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "VFouhg4IpsxX",
        "outputId": "4cd08fcd-0b60-4ac4-92dc-10deb0c7c17c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ATP             Tournament  Tournament_Int   Date  Series  Series_Int  \\\n",
              "0    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "1    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "2    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "3    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "4    1  BrisbaneInternational          1.2757  42737  ATP250      2.9693   \n",
              "\n",
              "     Court  Court_Int Surface  Surface_Int  ... Player1_Int     Player2  \\\n",
              "0  Outdoor     3.6494    Hard       4.4983  ...      6.7633  ThompsonJ.   \n",
              "1  Outdoor     3.6494    Hard       4.4983  ...      6.9297    RobertS.   \n",
              "2  Outdoor     3.6494    Hard       4.4983  ...      6.5792    FerrerD.   \n",
              "3  Outdoor     3.6494    Hard       4.4983  ...      6.8384  EscobedoE.   \n",
              "4  Outdoor     3.6494    Hard       4.4983  ...      6.7032  DimitrovG.   \n",
              "\n",
              "   Player2_Int Player1_Rank  Player2_Rank Player1_Odds  Player2_Odds  \\\n",
              "0       6.7926        160.0          79.0         3.50          1.29   \n",
              "1       6.9686         39.0          54.0         1.54          2.43   \n",
              "2       6.3881         26.0          21.0         1.77          2.01   \n",
              "3       6.0929         45.0         141.0         1.37          3.01   \n",
              "4       6.5157         33.0          17.0         2.85          1.41   \n",
              "\n",
              "  Player1_Implied_Prob  Player2_Implied_Prob  Class  \n",
              "0               0.2857                0.7752      0  \n",
              "1               0.6494                0.4115      0  \n",
              "2               0.5650                0.4975      1  \n",
              "3               0.7299                0.3322      1  \n",
              "4               0.3509                0.7092      0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-055c2fe5-7757-49ac-90f4-ea2398a5ae26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ATP</th>\n",
              "      <th>Tournament</th>\n",
              "      <th>Tournament_Int</th>\n",
              "      <th>Date</th>\n",
              "      <th>Series</th>\n",
              "      <th>Series_Int</th>\n",
              "      <th>Court</th>\n",
              "      <th>Court_Int</th>\n",
              "      <th>Surface</th>\n",
              "      <th>Surface_Int</th>\n",
              "      <th>...</th>\n",
              "      <th>Player1_Int</th>\n",
              "      <th>Player2</th>\n",
              "      <th>Player2_Int</th>\n",
              "      <th>Player1_Rank</th>\n",
              "      <th>Player2_Rank</th>\n",
              "      <th>Player1_Odds</th>\n",
              "      <th>Player2_Odds</th>\n",
              "      <th>Player1_Implied_Prob</th>\n",
              "      <th>Player2_Implied_Prob</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.7633</td>\n",
              "      <td>ThompsonJ.</td>\n",
              "      <td>6.7926</td>\n",
              "      <td>160.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.29</td>\n",
              "      <td>0.2857</td>\n",
              "      <td>0.7752</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.9297</td>\n",
              "      <td>RobertS.</td>\n",
              "      <td>6.9686</td>\n",
              "      <td>39.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1.54</td>\n",
              "      <td>2.43</td>\n",
              "      <td>0.6494</td>\n",
              "      <td>0.4115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.5792</td>\n",
              "      <td>FerrerD.</td>\n",
              "      <td>6.3881</td>\n",
              "      <td>26.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.77</td>\n",
              "      <td>2.01</td>\n",
              "      <td>0.5650</td>\n",
              "      <td>0.4975</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.8384</td>\n",
              "      <td>EscobedoE.</td>\n",
              "      <td>6.0929</td>\n",
              "      <td>45.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1.37</td>\n",
              "      <td>3.01</td>\n",
              "      <td>0.7299</td>\n",
              "      <td>0.3322</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>BrisbaneInternational</td>\n",
              "      <td>1.2757</td>\n",
              "      <td>42737</td>\n",
              "      <td>ATP250</td>\n",
              "      <td>2.9693</td>\n",
              "      <td>Outdoor</td>\n",
              "      <td>3.6494</td>\n",
              "      <td>Hard</td>\n",
              "      <td>4.4983</td>\n",
              "      <td>...</td>\n",
              "      <td>6.7032</td>\n",
              "      <td>DimitrovG.</td>\n",
              "      <td>6.5157</td>\n",
              "      <td>33.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.85</td>\n",
              "      <td>1.41</td>\n",
              "      <td>0.3509</td>\n",
              "      <td>0.7092</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-055c2fe5-7757-49ac-90f4-ea2398a5ae26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-055c2fe5-7757-49ac-90f4-ea2398a5ae26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-055c2fe5-7757-49ac-90f4-ea2398a5ae26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lisCol = [\"ATP\",\"Tournament\",\"Series\",\"Court\",\"Surface\",\"Player1\",\"Player2\",\"Winner\",\"Round\"]\n",
        "df2=dataset.drop(lisCol, axis = 1)\n",
        "print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bSeVvdjqMK2W",
        "outputId": "458503f5-4c6a-4d94-df8c-77b7d0528938"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Tournament_Int   Date  Series_Int  Court_Int  Surface_Int  Round_Int  \\\n",
            "0              1.2757  42737      2.9693     3.6494       4.4983     5.1257   \n",
            "1              1.2757  42737      2.9693     3.6494       4.4983     5.1257   \n",
            "2              1.2757  42737      2.9693     3.6494       4.4983     5.1257   \n",
            "3              1.2757  42737      2.9693     3.6494       4.4983     5.1257   \n",
            "4              1.2757  42737      2.9693     3.6494       4.4983     5.1257   \n",
            "...               ...    ...         ...        ...          ...        ...   \n",
            "14730          1.7532  41223      2.7079     3.2579       4.4983     5.9542   \n",
            "14731          1.7532  41223      2.7079     3.2579       4.4983     5.9542   \n",
            "14732          1.7532  41224      2.7079     3.2579       4.4983     5.2101   \n",
            "14733          1.7532  41224      2.7079     3.2579       4.4983     5.2101   \n",
            "14734          1.7532  41225      2.7079     3.2579       4.4983     5.3011   \n",
            "\n",
            "       Best_of  Winner_Int  Player1_Int  Player2_Int  Player1_Rank  \\\n",
            "0            3      6.7926       6.7633       6.7926         160.0   \n",
            "1            3      6.9297       6.9297       6.9686          39.0   \n",
            "2            3      6.3881       6.5792       6.3881          26.0   \n",
            "3            3      6.8384       6.8384       6.0929          45.0   \n",
            "4            3      6.5157       6.7032       6.5157          33.0   \n",
            "...        ...         ...          ...          ...           ...   \n",
            "14730        3      6.0310       6.9997       6.0310           2.0   \n",
            "14731        3      6.3881       6.3881       6.5461           5.0   \n",
            "14732        3      6.9457       6.0310       6.9457           7.0   \n",
            "14733        3      6.9997       6.9997       6.2537           2.0   \n",
            "14734        3      6.9457       6.9997       6.9457           2.0   \n",
            "\n",
            "       Player2_Rank  Player1_Odds  Player2_Odds  Player1_Implied_Prob  \\\n",
            "0              79.0          3.50          1.29                0.2857   \n",
            "1              54.0          1.54          2.43                0.6494   \n",
            "2              21.0          1.77          2.01                0.5650   \n",
            "3             141.0          1.37          3.01                0.7299   \n",
            "4              17.0          2.85          1.41                0.3509   \n",
            "...             ...           ...           ...                   ...   \n",
            "14730           7.0          1.42          2.82                0.7042   \n",
            "14731           9.0          1.20          4.55                0.8333   \n",
            "14732           1.0          4.28          1.22                0.2336   \n",
            "14733           3.0          2.16          1.68                0.4630   \n",
            "14734           1.0          2.26          1.64                0.4425   \n",
            "\n",
            "       Player2_Implied_Prob  Class  \n",
            "0                    0.7752      0  \n",
            "1                    0.4115      0  \n",
            "2                    0.4975      1  \n",
            "3                    0.3322      1  \n",
            "4                    0.7092      0  \n",
            "...                     ...    ...  \n",
            "14730                0.3546      1  \n",
            "14731                0.2198      1  \n",
            "14732                0.8197      1  \n",
            "14733                0.5952      1  \n",
            "14734                0.6098      1  \n",
            "\n",
            "[14735 rows x 17 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc=StandardScaler()\n",
        "df2['Player1_Rank'] = sc.fit_transform(df2['Player1_Rank'].values.reshape(-1, 1))\n",
        "df2['Player2_Rank'] = sc.fit_transform(df2['Player2_Rank'].values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "JygrAat26gJ-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = dataset.values\n",
        "labels = raw_data[:, -1]\n",
        "data = raw_data[:, 0:-1]\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=2021\n",
        ")"
      ],
      "metadata": {
        "id": "LRC2f8B0QQD8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_labels.astype(bool)\n",
        "test_labels = test_labels.astype(bool)\n",
        "#creating normal and abnormal datasets\n",
        "normal_train_data = train_data[~train_labels]\n",
        "normal_test_data = test_data[~test_labels]\n",
        "abnormal_train_data = train_data[train_labels]\n",
        "abnormal_test_data = test_data[test_labels]\n",
        "print(\" No. of records in Abnormal Train Data=\",len(abnormal_train_data))\n",
        "print(\" No. of records in Normal Train data=\",len(normal_train_data))\n",
        "print(\" No. of records in Abnormal Test Data=\",len(abnormal_test_data))\n",
        "print(\" No. of records in Normal Test data=\",len(normal_test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qRyQTU0wQVhD",
        "outputId": "9cf60023-a788-4d98-e76a-6adff284c181"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No. of records in Abnormal Train Data= 1595\n",
            " No. of records in Normal Train data= 10193\n",
            " No. of records in Abnormal Test Data= 367\n",
            " No. of records in Normal Test data= 2580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epoch = 50\n",
        "batch_size = 64\n",
        "input_dim = normal_train_data.shape[1] #num of columns, 30\n",
        "encoding_dim = 14\n",
        "hidden_dim_1 = int(encoding_dim / 2) #\n",
        "hidden_dim_2=4  \n",
        "learning_rate = 1e-7"
      ],
      "metadata": {
        "id": "AI2E4Y0-VX_B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input Layer\n",
        "input_layer = tf.keras.layers.Input(shape=(input_dim, ))\n",
        "#Encoder\n",
        "encoder = tf.keras.layers.Dense(encoding_dim, activation=\"tanh\",                                \n",
        "activity_regularizer=tf.keras.regularizers.l2(learning_rate))(input_layer)\n",
        "encoder=tf.keras.layers.Dropout(0.2)(encoder)\n",
        "encoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
        "encoder = tf.keras.layers.Dense(hidden_dim_2, activation=tf.nn.leaky_relu)(encoder)\n",
        "# Decoder\n",
        "decoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
        "decoder=tf.keras.layers.Dropout(0.2)(decoder)\n",
        "decoder = tf.keras.layers.Dense(encoding_dim, activation='relu')(decoder)\n",
        "decoder = tf.keras.layers.Dense(input_dim, activation='tanh')(decoder)\n",
        "#Autoencoder\n",
        "autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uu5XhowTWfX9",
        "outputId": "39165a8c-9a41-4e2c-f02b-cb71f6644ab4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 25)]              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 14)                364       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 14)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 7)                 105       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 7)                 35        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 14)                112       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 25)                375       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,023\n",
            "Trainable params: 1,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp = tf.keras.callbacks.ModelCheckpoint(filepath=\"autoencoder_abnormal.h5\",\n",
        "mode='min', monitor='val_loss', verbose=2, save_best_only=True)\n",
        "# define our early stopping\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.0001,\n",
        "    patience=10,\n",
        "    verbose=1, \n",
        "    mode='min',\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "AvB-2EvldKEg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss='mean_squared_error',\n",
        "                    optimizer='adam')"
      ],
      "metadata": {
        "id": "sAj-mwB8hvQD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = tf.expand_dims(tf.linspace(0., 2*3.14, 1000), -1)\n",
        "noise = tf.random.normal((1000, 2), stddev=0.05)\n",
        "points = tf.concat([tf.cos(t), tf.sin(t)], axis=1) + noise"
      ],
      "metadata": {
        "id": "zmyhPWXqtYbc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_points = tf.random.shuffle(points)\n",
        "\n",
        "encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1) # one-dimensional output\n",
        "])\n",
        "\n",
        "decoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(2) # decode to two dimensions again\n",
        "])\n",
        "\n",
        "autoencoder = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    decoder\n",
        "])\n",
        "\n",
        "autoencoder.compile(loss=\"mse\")\n",
        "\n",
        "autoencoder.fit(\n",
        "    x=shuffled_points, # goal is that output is \n",
        "    y=shuffled_points, # close to the same input\n",
        "    validation_split=0.2, # to check if the model is generalizing\n",
        "    epochs=500\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SN04HZZOtVjF",
        "outputId": "a57a577e-bdab-483c-b698-1ca2b5d18f06"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "25/25 [==============================] - 1s 14ms/step - loss: 0.4144 - val_loss: 0.3127\n",
            "Epoch 2/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2740 - val_loss: 0.2509\n",
            "Epoch 3/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2507 - val_loss: 0.2450\n",
            "Epoch 4/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2414 - val_loss: 0.2343\n",
            "Epoch 5/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2261 - val_loss: 0.2155\n",
            "Epoch 6/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2046 - val_loss: 0.1916\n",
            "Epoch 7/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1786 - val_loss: 0.1691\n",
            "Epoch 8/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1522\n",
            "Epoch 9/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1298 - val_loss: 0.1296\n",
            "Epoch 10/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1152 - val_loss: 0.1138\n",
            "Epoch 11/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.1017\n",
            "Epoch 12/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.0971\n",
            "Epoch 13/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0802 - val_loss: 0.0879\n",
            "Epoch 14/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.0775\n",
            "Epoch 15/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0664 - val_loss: 0.0726\n",
            "Epoch 16/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0616 - val_loss: 0.0669\n",
            "Epoch 17/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0562 - val_loss: 0.0650\n",
            "Epoch 18/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0551 - val_loss: 0.0629\n",
            "Epoch 19/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0513 - val_loss: 0.0551\n",
            "Epoch 20/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0560\n",
            "Epoch 21/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0453 - val_loss: 0.0478\n",
            "Epoch 22/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.0513\n",
            "Epoch 23/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0429 - val_loss: 0.0512\n",
            "Epoch 24/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0488\n",
            "Epoch 25/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0480\n",
            "Epoch 26/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0579\n",
            "Epoch 27/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0436\n",
            "Epoch 28/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0373 - val_loss: 0.0343\n",
            "Epoch 29/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0319\n",
            "Epoch 30/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0329\n",
            "Epoch 31/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0421\n",
            "Epoch 32/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0269\n",
            "Epoch 33/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 0.0398\n",
            "Epoch 34/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0333\n",
            "Epoch 35/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0384\n",
            "Epoch 36/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0242\n",
            "Epoch 37/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0242\n",
            "Epoch 38/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0213\n",
            "Epoch 39/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0256\n",
            "Epoch 40/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0210\n",
            "Epoch 41/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0245 - val_loss: 0.0263\n",
            "Epoch 42/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0334\n",
            "Epoch 43/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0261\n",
            "Epoch 44/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0327\n",
            "Epoch 45/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0177\n",
            "Epoch 46/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0167\n",
            "Epoch 47/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0156\n",
            "Epoch 48/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.0221\n",
            "Epoch 49/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0164\n",
            "Epoch 50/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0137\n",
            "Epoch 51/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0141\n",
            "Epoch 52/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0181\n",
            "Epoch 53/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0172\n",
            "Epoch 54/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0124\n",
            "Epoch 55/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0215\n",
            "Epoch 56/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0217\n",
            "Epoch 57/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0127\n",
            "Epoch 58/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0128\n",
            "Epoch 59/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0136\n",
            "Epoch 60/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0165\n",
            "Epoch 61/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0181\n",
            "Epoch 62/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0374\n",
            "Epoch 63/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0121\n",
            "Epoch 64/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0102\n",
            "Epoch 65/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0194\n",
            "Epoch 66/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0171\n",
            "Epoch 67/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0117\n",
            "Epoch 68/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0532\n",
            "Epoch 69/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0083\n",
            "Epoch 70/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0211\n",
            "Epoch 71/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0174\n",
            "Epoch 72/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0121\n",
            "Epoch 73/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0113\n",
            "Epoch 74/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0097\n",
            "Epoch 75/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0186\n",
            "Epoch 76/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0381\n",
            "Epoch 77/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0231\n",
            "Epoch 78/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0148\n",
            "Epoch 79/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0157\n",
            "Epoch 80/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0165\n",
            "Epoch 81/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0105\n",
            "Epoch 82/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0118\n",
            "Epoch 83/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0109\n",
            "Epoch 84/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0079\n",
            "Epoch 85/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0093\n",
            "Epoch 86/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0124\n",
            "Epoch 87/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0075\n",
            "Epoch 88/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0090\n",
            "Epoch 89/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0103\n",
            "Epoch 90/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0099\n",
            "Epoch 91/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0107\n",
            "Epoch 92/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0156\n",
            "Epoch 93/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0283\n",
            "Epoch 94/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0272\n",
            "Epoch 95/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0252\n",
            "Epoch 96/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0294\n",
            "Epoch 97/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0175\n",
            "Epoch 98/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0324\n",
            "Epoch 99/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0149\n",
            "Epoch 100/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0094\n",
            "Epoch 101/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0171\n",
            "Epoch 102/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0256\n",
            "Epoch 103/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0137\n",
            "Epoch 104/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0205\n",
            "Epoch 105/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0076\n",
            "Epoch 106/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0075\n",
            "Epoch 107/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0179\n",
            "Epoch 108/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0130\n",
            "Epoch 109/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0308\n",
            "Epoch 110/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0051\n",
            "Epoch 111/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0246 - val_loss: 0.0222\n",
            "Epoch 112/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0278\n",
            "Epoch 113/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0205\n",
            "Epoch 114/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0194\n",
            "Epoch 115/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0230\n",
            "Epoch 116/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0122\n",
            "Epoch 117/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0234\n",
            "Epoch 118/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0133\n",
            "Epoch 119/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0139\n",
            "Epoch 120/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0204\n",
            "Epoch 121/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0208\n",
            "Epoch 122/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0108\n",
            "Epoch 123/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0070\n",
            "Epoch 124/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0267\n",
            "Epoch 125/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0255\n",
            "Epoch 126/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0316\n",
            "Epoch 127/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0183\n",
            "Epoch 128/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0266\n",
            "Epoch 129/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0130\n",
            "Epoch 130/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0146\n",
            "Epoch 131/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0226\n",
            "Epoch 132/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0188\n",
            "Epoch 133/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0127\n",
            "Epoch 134/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0140\n",
            "Epoch 135/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0293\n",
            "Epoch 136/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0147\n",
            "Epoch 137/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0223\n",
            "Epoch 138/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0230\n",
            "Epoch 139/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0142\n",
            "Epoch 140/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0259\n",
            "Epoch 141/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0387\n",
            "Epoch 142/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0165\n",
            "Epoch 143/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0141\n",
            "Epoch 144/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0193\n",
            "Epoch 145/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0195\n",
            "Epoch 146/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0232\n",
            "Epoch 147/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0169\n",
            "Epoch 148/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0147\n",
            "Epoch 149/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0340\n",
            "Epoch 150/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0302\n",
            "Epoch 151/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0140\n",
            "Epoch 152/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0136\n",
            "Epoch 153/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0128\n",
            "Epoch 154/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0155\n",
            "Epoch 155/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0448\n",
            "Epoch 156/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0135\n",
            "Epoch 157/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0225\n",
            "Epoch 158/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0125\n",
            "Epoch 159/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0138\n",
            "Epoch 160/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0225\n",
            "Epoch 161/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0127\n",
            "Epoch 162/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0132\n",
            "Epoch 163/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0310\n",
            "Epoch 164/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0269\n",
            "Epoch 165/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0164\n",
            "Epoch 166/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0132\n",
            "Epoch 167/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0348\n",
            "Epoch 168/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0308\n",
            "Epoch 169/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0366\n",
            "Epoch 170/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0224\n",
            "Epoch 171/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0260\n",
            "Epoch 172/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0219\n",
            "Epoch 173/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0303\n",
            "Epoch 174/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0155\n",
            "Epoch 175/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0268\n",
            "Epoch 176/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0265\n",
            "Epoch 177/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0273\n",
            "Epoch 178/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0136\n",
            "Epoch 179/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0199\n",
            "Epoch 180/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0242\n",
            "Epoch 181/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0509\n",
            "Epoch 182/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0301\n",
            "Epoch 183/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0152\n",
            "Epoch 184/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0296\n",
            "Epoch 185/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0216\n",
            "Epoch 186/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0187\n",
            "Epoch 187/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0287\n",
            "Epoch 188/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0175\n",
            "Epoch 189/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0281\n",
            "Epoch 190/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0181\n",
            "Epoch 191/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0121\n",
            "Epoch 192/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0440\n",
            "Epoch 193/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0184\n",
            "Epoch 194/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0346\n",
            "Epoch 195/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0169\n",
            "Epoch 196/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0091\n",
            "Epoch 197/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0098\n",
            "Epoch 198/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0339\n",
            "Epoch 199/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0165\n",
            "Epoch 200/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0211\n",
            "Epoch 201/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0287\n",
            "Epoch 202/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0190\n",
            "Epoch 203/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0268\n",
            "Epoch 204/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0225\n",
            "Epoch 205/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0099\n",
            "Epoch 206/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0101\n",
            "Epoch 207/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0195\n",
            "Epoch 208/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0201\n",
            "Epoch 209/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0629\n",
            "Epoch 210/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0164\n",
            "Epoch 211/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0067\n",
            "Epoch 212/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0043\n",
            "Epoch 213/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0124\n",
            "Epoch 214/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0050\n",
            "Epoch 215/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0035\n",
            "Epoch 216/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0111\n",
            "Epoch 217/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0045\n",
            "Epoch 218/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0119\n",
            "Epoch 219/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0148\n",
            "Epoch 220/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0263\n",
            "Epoch 221/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0104\n",
            "Epoch 222/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0134\n",
            "Epoch 223/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0037\n",
            "Epoch 224/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0102\n",
            "Epoch 225/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0101\n",
            "Epoch 226/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0081\n",
            "Epoch 227/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0081\n",
            "Epoch 228/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0054\n",
            "Epoch 229/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0031\n",
            "Epoch 230/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0032\n",
            "Epoch 231/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0064\n",
            "Epoch 232/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0183\n",
            "Epoch 233/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0073\n",
            "Epoch 234/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.0114\n",
            "Epoch 235/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0050\n",
            "Epoch 236/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0202\n",
            "Epoch 237/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0330\n",
            "Epoch 238/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0092\n",
            "Epoch 239/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0361\n",
            "Epoch 240/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0043\n",
            "Epoch 241/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0362\n",
            "Epoch 242/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0218\n",
            "Epoch 243/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0318\n",
            "Epoch 244/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0189\n",
            "Epoch 245/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0292\n",
            "Epoch 246/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0286\n",
            "Epoch 247/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0181\n",
            "Epoch 248/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0442\n",
            "Epoch 249/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0101\n",
            "Epoch 250/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0112\n",
            "Epoch 251/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0122\n",
            "Epoch 252/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0218\n",
            "Epoch 253/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0354\n",
            "Epoch 254/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0091\n",
            "Epoch 255/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0070\n",
            "Epoch 256/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0254\n",
            "Epoch 257/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0078\n",
            "Epoch 258/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0234\n",
            "Epoch 259/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0247\n",
            "Epoch 260/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0134\n",
            "Epoch 261/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0354\n",
            "Epoch 262/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0062\n",
            "Epoch 263/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0277\n",
            "Epoch 264/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0101\n",
            "Epoch 265/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0288\n",
            "Epoch 266/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0203\n",
            "Epoch 267/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0339\n",
            "Epoch 268/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0219\n",
            "Epoch 269/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0085\n",
            "Epoch 270/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0199\n",
            "Epoch 271/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 272/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0301\n",
            "Epoch 273/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0102\n",
            "Epoch 274/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0135\n",
            "Epoch 275/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0434\n",
            "Epoch 276/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0249\n",
            "Epoch 277/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0207\n",
            "Epoch 278/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0228\n",
            "Epoch 279/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0115\n",
            "Epoch 280/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0373\n",
            "Epoch 281/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0223\n",
            "Epoch 282/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0101\n",
            "Epoch 283/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0039\n",
            "Epoch 284/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0191\n",
            "Epoch 285/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0218\n",
            "Epoch 286/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0154\n",
            "Epoch 287/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0065\n",
            "Epoch 288/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0146\n",
            "Epoch 289/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0111\n",
            "Epoch 290/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0205 - val_loss: 0.0163\n",
            "Epoch 291/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0141\n",
            "Epoch 292/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0094\n",
            "Epoch 293/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0143\n",
            "Epoch 294/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0202\n",
            "Epoch 295/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0143\n",
            "Epoch 296/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0094\n",
            "Epoch 297/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0195\n",
            "Epoch 298/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0341\n",
            "Epoch 299/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0118\n",
            "Epoch 300/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0087\n",
            "Epoch 301/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0106\n",
            "Epoch 302/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0075\n",
            "Epoch 303/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0088\n",
            "Epoch 304/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0229\n",
            "Epoch 305/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0382\n",
            "Epoch 306/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0201\n",
            "Epoch 307/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0423\n",
            "Epoch 308/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0029\n",
            "Epoch 309/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0218\n",
            "Epoch 310/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0131\n",
            "Epoch 311/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0230 - val_loss: 0.0130\n",
            "Epoch 312/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0079\n",
            "Epoch 313/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0216\n",
            "Epoch 314/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0379\n",
            "Epoch 315/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0283\n",
            "Epoch 316/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0114\n",
            "Epoch 317/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0052\n",
            "Epoch 318/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0129\n",
            "Epoch 319/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0063\n",
            "Epoch 320/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0123\n",
            "Epoch 321/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0061\n",
            "Epoch 322/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0296\n",
            "Epoch 323/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0089\n",
            "Epoch 324/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0190\n",
            "Epoch 325/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0246\n",
            "Epoch 326/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0111\n",
            "Epoch 327/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0058\n",
            "Epoch 328/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0127\n",
            "Epoch 329/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0520\n",
            "Epoch 330/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0198\n",
            "Epoch 331/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0205\n",
            "Epoch 332/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0070\n",
            "Epoch 333/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0117\n",
            "Epoch 334/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0139\n",
            "Epoch 335/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0190\n",
            "Epoch 336/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0139\n",
            "Epoch 337/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0097\n",
            "Epoch 338/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0613\n",
            "Epoch 339/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0305\n",
            "Epoch 340/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0278\n",
            "Epoch 341/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.0237\n",
            "Epoch 342/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0183\n",
            "Epoch 343/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.0102\n",
            "Epoch 344/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0091\n",
            "Epoch 345/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0032\n",
            "Epoch 346/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0076\n",
            "Epoch 347/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0105\n",
            "Epoch 348/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0243\n",
            "Epoch 349/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0168\n",
            "Epoch 350/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0052\n",
            "Epoch 351/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0082\n",
            "Epoch 352/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0058\n",
            "Epoch 353/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0040\n",
            "Epoch 354/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0053\n",
            "Epoch 355/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0100\n",
            "Epoch 356/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0124\n",
            "Epoch 357/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0156\n",
            "Epoch 358/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0056\n",
            "Epoch 359/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0240\n",
            "Epoch 360/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0094\n",
            "Epoch 361/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0028\n",
            "Epoch 362/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0156\n",
            "Epoch 363/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0131\n",
            "Epoch 364/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0091\n",
            "Epoch 365/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0060\n",
            "Epoch 366/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0152\n",
            "Epoch 367/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0107\n",
            "Epoch 368/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0040\n",
            "Epoch 369/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0202\n",
            "Epoch 370/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0122\n",
            "Epoch 371/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0034\n",
            "Epoch 372/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0106\n",
            "Epoch 373/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0071\n",
            "Epoch 374/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0218\n",
            "Epoch 375/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0028\n",
            "Epoch 376/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0060\n",
            "Epoch 377/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0212\n",
            "Epoch 378/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0067\n",
            "Epoch 379/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0077\n",
            "Epoch 380/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0088\n",
            "Epoch 381/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0027\n",
            "Epoch 382/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0054\n",
            "Epoch 383/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0031\n",
            "Epoch 384/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0044\n",
            "Epoch 385/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0037\n",
            "Epoch 386/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0025\n",
            "Epoch 387/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0102\n",
            "Epoch 388/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0139\n",
            "Epoch 389/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0138\n",
            "Epoch 390/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0170\n",
            "Epoch 391/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0071\n",
            "Epoch 392/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0058\n",
            "Epoch 393/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0158\n",
            "Epoch 394/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0022\n",
            "Epoch 395/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0042\n",
            "Epoch 396/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0023\n",
            "Epoch 397/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0131\n",
            "Epoch 398/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0031\n",
            "Epoch 399/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0132\n",
            "Epoch 400/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0021\n",
            "Epoch 401/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0165\n",
            "Epoch 402/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0072\n",
            "Epoch 403/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0033\n",
            "Epoch 404/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0038\n",
            "Epoch 405/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0029\n",
            "Epoch 406/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0037\n",
            "Epoch 407/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0050\n",
            "Epoch 408/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0029\n",
            "Epoch 409/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0128\n",
            "Epoch 410/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0273\n",
            "Epoch 411/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0048\n",
            "Epoch 412/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0073\n",
            "Epoch 413/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0066\n",
            "Epoch 414/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0023\n",
            "Epoch 415/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0063\n",
            "Epoch 416/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0031\n",
            "Epoch 417/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0109\n",
            "Epoch 418/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0036\n",
            "Epoch 419/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0042\n",
            "Epoch 420/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0051\n",
            "Epoch 421/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0018\n",
            "Epoch 422/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0043\n",
            "Epoch 423/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0049\n",
            "Epoch 424/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0040\n",
            "Epoch 425/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0025\n",
            "Epoch 426/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0198\n",
            "Epoch 427/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0238\n",
            "Epoch 428/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0021\n",
            "Epoch 429/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0050\n",
            "Epoch 430/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0021\n",
            "Epoch 431/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0090\n",
            "Epoch 432/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0047\n",
            "Epoch 433/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0025\n",
            "Epoch 434/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0026\n",
            "Epoch 435/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0063\n",
            "Epoch 436/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0203\n",
            "Epoch 437/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0194\n",
            "Epoch 438/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0036\n",
            "Epoch 439/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0042\n",
            "Epoch 440/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0084\n",
            "Epoch 441/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0059\n",
            "Epoch 442/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0048\n",
            "Epoch 443/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0061\n",
            "Epoch 444/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0138\n",
            "Epoch 445/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0202\n",
            "Epoch 446/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.0283\n",
            "Epoch 447/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0417\n",
            "Epoch 448/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0387 - val_loss: 0.0320\n",
            "Epoch 449/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0322 - val_loss: 0.0264\n",
            "Epoch 450/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0318 - val_loss: 0.0235\n",
            "Epoch 451/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0563\n",
            "Epoch 452/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0298 - val_loss: 0.0081\n",
            "Epoch 453/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0236 - val_loss: 0.0122\n",
            "Epoch 454/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0098\n",
            "Epoch 455/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0380\n",
            "Epoch 456/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0699\n",
            "Epoch 457/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0327 - val_loss: 0.0613\n",
            "Epoch 458/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0149\n",
            "Epoch 459/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0074\n",
            "Epoch 460/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0218 - val_loss: 0.0101\n",
            "Epoch 461/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0092\n",
            "Epoch 462/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0111\n",
            "Epoch 463/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0108\n",
            "Epoch 464/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0056\n",
            "Epoch 465/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0103\n",
            "Epoch 466/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0067\n",
            "Epoch 467/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 0.0092\n",
            "Epoch 468/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0229\n",
            "Epoch 469/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0039\n",
            "Epoch 470/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0034\n",
            "Epoch 471/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0206 - val_loss: 0.0228\n",
            "Epoch 472/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0347\n",
            "Epoch 473/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.0214\n",
            "Epoch 474/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0026\n",
            "Epoch 475/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0399\n",
            "Epoch 476/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0304\n",
            "Epoch 477/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0751\n",
            "Epoch 478/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0036\n",
            "Epoch 479/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 480/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0176\n",
            "Epoch 481/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0288\n",
            "Epoch 482/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0033\n",
            "Epoch 483/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0173\n",
            "Epoch 484/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0027\n",
            "Epoch 485/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0206\n",
            "Epoch 486/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0029\n",
            "Epoch 487/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0024\n",
            "Epoch 488/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0631\n",
            "Epoch 489/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0349\n",
            "Epoch 490/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.0289\n",
            "Epoch 491/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0359\n",
            "Epoch 492/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0278\n",
            "Epoch 493/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0346 - val_loss: 0.0393\n",
            "Epoch 494/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0506\n",
            "Epoch 495/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0226\n",
            "Epoch 496/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0692\n",
            "Epoch 497/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0597\n",
            "Epoch 498/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0349 - val_loss: 0.0275\n",
            "Epoch 499/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0468 - val_loss: 0.0272\n",
            "Epoch 500/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0340 - val_loss: 0.0273\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f154323e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}